# ==========================================================
# ENV_SETUP.PY
# Proyecto: Liga 1 Per√∫ - Configuraci√≥n Universal Inteligente
# Autor: Oscar Garc√≠a Del √Åguila
# Versi√≥n: 3.8.3 (Usa Git Snapshot Commit + Auto Update)
# ==========================================================

import os, sys, subprocess, tempfile, warnings
from pyspark.sql import SparkSession

warnings.filterwarnings("ignore")

# ----------------------------------------------------------
# DETECTAR RA√çZ DEL REPO
# ----------------------------------------------------------
def detect_repo_root(verbose=False) -> str:
    try:
        cwd = os.getcwd()

        # Caso Job Git (.internal)
        if "/Repos/.internal" in cwd:
            parts = cwd.split("/Repos/.internal/")[1].split("/")
            commit_hash = parts[0]
            repo_root = f"/Workspace/Repos/.internal/{commit_hash}"

            subdirs = [d for d in os.listdir(repo_root) if os.path.isdir(os.path.join(repo_root, d))]
            if subdirs:
                repo_root = os.path.join(repo_root, subdirs[0])

            if verbose:
                print(f"[ENV_SETUP] Modo Job Git (.internal) detectado ‚Üí {repo_root}")
            return repo_root

        # Caso Workspace interactivo
        elif "/Repos/" in cwd:
            parts = cwd.split("/Repos/")[1].split("/")
            repo_root = f"/Workspace/Repos/{parts[0]}/{parts[1]}"
            if verbose:
                print(f"[ENV_SETUP] Modo interactivo detectado ‚Üí {repo_root}")
            return repo_root

        # Caso local o fallback
        else:
            if verbose:
                print(f"[ENV_SETUP] Modo local detectado ‚Üí {cwd}")
            return cwd
    except Exception as e:
        raise Exception(f"[ENV_SETUP ERROR] No se pudo detectar la ra√≠z del repo: {e}")

# ----------------------------------------------------------
# OBTENER COMMIT DEL SNAPSHOT DEL JOB
# ----------------------------------------------------------
def get_job_snapshot_commit(repo_root):
    """Obtiene el commit del snapshot que Databricks est√° usando"""
    try:
        if "/Repos/.internal" in repo_root:
            # Extraer el commit del path del snapshot
            commit_hash = repo_root.split("/.internal/")[1].split("/")[0]
            print(f"[ENV_SETUP] Commit del Snapshot del Job: {commit_hash}")
            return commit_hash
        return None
    except Exception as e:
        print(f"[ENV_SETUP WARN] No se pudo obtener commit del snapshot: {e}")
        return None

# ----------------------------------------------------------
# OBTENER √öLTIMO COMMIT DE GITHUB
# ----------------------------------------------------------
def get_latest_github_commit(remote_url="https://github.com/oscarmilan30/liga1-azure.git", branch="main"):
    """Obtiene el √∫ltimo commit de GitHub sin clonar el repo completo"""
    try:
        print(f"[ENV_SETUP] Obteniendo √∫ltimo commit de GitHub...")
        print(f"[ENV_SETUP]   Repo: {remote_url}")
        print(f"[ENV_SETUP]   Rama: {branch}")
        
        # Usar git ls-remote para obtener el √∫ltimo commit sin clonar
        result = subprocess.run(
            ["git", "ls-remote", remote_url, f"refs/heads/{branch}"],
            capture_output=True, text=True, timeout=30
        )
        
        if result.returncode == 0:
            latest_commit = result.stdout.split()[0]
            short_commit = latest_commit[:7]
            print(f"[ENV_SETUP]   √öltimo commit en GitHub: {short_commit}")
            return latest_commit, short_commit
        else:
            print(f"[ENV_SETUP WARN] Error al obtener √∫ltimo commit: {result.stderr}")
            return None, None
    except Exception as e:
        print(f"[ENV_SETUP WARN] No se pudo obtener √∫ltimo commit de GitHub: {e}")
        return None, None

# ----------------------------------------------------------
# SINCRONIZACI√ìN INTELIGENTE CON GITHUB
# ----------------------------------------------------------
def smart_git_sync(repo_root, verbose=False):
    """Sincroniza solo si el snapshot est√° desactualizado"""
    try:
        if "/Repos/.internal" not in repo_root:
            return repo_root  # No aplica
        
        remote_url = "https://github.com/oscarmilan30/liga1-azure.git"
        branch = "main"
        
        # Obtener informaci√≥n de commits
        snapshot_commit = get_job_snapshot_commit(repo_root)
        latest_commit, latest_short = get_latest_github_commit(remote_url, branch)
        
        if not latest_commit:
            print(f"[ENV_SETUP] No se pudo verificar GitHub, usando snapshot del Job")
            return repo_root
        
        # Verificar si el snapshot est√° actualizado
        if snapshot_commit and latest_commit.startswith(snapshot_commit):
            print(f"[ENV_SETUP] El snapshot del Job est√° ACTUALIZADO (commit: {snapshot_commit})")
            return repo_root
        else:
            print(f"[ENV_SETUP] El snapshot est√° DESACTUALIZADO")
            print(f"[ENV_SETUP]   Snapshot: {snapshot_commit}")
            print(f"[ENV_SETUP]   GitHub:   {latest_short}")
            print(f"[ENV_SETUP]   Actualizando c√≥digo...")
            
            # Clonar/actualizar el repo
            tmp_dir = os.path.join(tempfile.gettempdir(), f"liga1_github_{latest_short}")
            
            if not os.path.exists(tmp_dir):
                print(f"[ENV_SETUP]   Clonando √∫ltimo c√≥digo de GitHub...")
                result = subprocess.run(
                    ["git", "clone", "-b", branch, remote_url, tmp_dir],
                    capture_output=True, text=True, timeout=120
                )
                if result.returncode != 0:
                    print(f"[ENV_SETUP ERROR] Clone fall√≥: {result.stderr}")
                    return repo_root
            else:
                print(f"[ENV_SETUP]   Actualizando repo existente...")
                # Reset al √∫ltimo commit
                subprocess.run(["git", "-C", tmp_dir, "fetch"], capture_output=True)
                subprocess.run(["git", "-C", tmp_dir, "reset", "--hard", f"origin/{branch}"], capture_output=True)
            
            # Verificar el commit actual
            current_commit = subprocess.check_output(
                ["git", "-C", tmp_dir, "rev-parse", "--short", "HEAD"]
            ).decode().strip()
            
            print(f"[ENV_SETUP]   C√≥digo actualizado a commit: {current_commit}")
            return tmp_dir
            
    except Exception as e:
        print(f"[ENV_SETUP ERROR] Error en sincronizaci√≥n: {e}")
        return repo_root

# ----------------------------------------------------------
# CONSTRUCCI√ìN DE RUTA ABSOLUTA (para YAML, etc.)
# ----------------------------------------------------------
def get_workspace_path(relative_path: str) -> str:
    repo_root = detect_repo_root()
    clean_relative = relative_path.lstrip("/")
    full_path = os.path.join(repo_root, clean_relative)
    print(f"[ENV_SETUP] Ruta absoluta generada: {full_path}")
    return full_path

# ----------------------------------------------------------
# AUTO IMPORTACI√ìN DE M√ìDULOS (DIN√ÅMICO)
# ----------------------------------------------------------
def auto_import_modules(repo_root: str, verbose=False, depth=2):
    added = []
    invalid = [".git", ".github", "__pycache__", ".idea", ".vscode", "venv"]

    for root, dirs, _ in os.walk(repo_root):
        if root[len(repo_root):].count(os.sep) > depth:
            continue
        for d in dirs:
            if not any(d.startswith(i) for i in invalid):
                full_path = os.path.join(root, d)
                if os.path.isdir(full_path) and full_path not in sys.path:
                    sys.path.append(full_path)
                    added.append(full_path)
    if verbose:
        print("[ENV_SETUP] Carpetas a√±adidas din√°micamente:")
        for p in added:
            print(f"  - {p.replace(repo_root, '') or '/'}")
    return added

# ----------------------------------------------------------
# SPARK SAFE INITIALIZATION
# ----------------------------------------------------------
def get_or_create_spark(verbose=False):
    try:
        spark = SparkSession.getActiveSession()
        if spark is None:
            spark = (
                SparkSession.builder
                .config("spark.databricks.connect.enabled", "false")
                .config("spark.databricks.session.share", "false")
                .getOrCreate()
            )
            if verbose:
                print("[ENV_SETUP] Nueva sesi√≥n Spark creada.")
        else:
            if verbose:
                print("[ENV_SETUP] Sesi√≥n Spark reutilizada.")
        return spark
    except Exception as e:
        raise Exception(f"[ENV_SETUP ERROR] No se pudo crear/obtener SparkSession: {e}")

# ----------------------------------------------------------
# INICIALIZACI√ìN AUTOM√ÅTICA - MEJORADA
# ----------------------------------------------------------
try:
    # Detectar ra√≠z del repo
    repo_root = detect_repo_root()
    print(f"[ENV_SETUP] Ra√≠z del repo detectada: {repo_root}")
    
    # Obtener informaci√≥n del snapshot
    snapshot_commit = get_job_snapshot_commit(repo_root)

    # SINCRONIZACI√ìN INTELIGENTE
    if "/Repos/.internal" in repo_root:
        print(f"[ENV_SETUP] üöÄ MODO JOB GIT DETECTADO")
        repo_root = smart_git_sync(repo_root, verbose=True)
        print(f"[ENV_SETUP] Nueva ra√≠z del repo: {repo_root}")

    # Asegurar sys.path
    if repo_root not in sys.path:
        sys.path.append(repo_root)

    # Auto-importar m√≥dulos
    added = auto_import_modules(repo_root, verbose=True)
    
    # Crear sesi√≥n Spark
    spark = get_or_create_spark(verbose=True)

    print(f"[ENV_SETUP] INICIALIZACI√ìN COMPLETADA EXITOSAMENTE")
    print(f"[ENV_SETUP] Directorio activo: {repo_root}")

except Exception as e:
    print(f"[ENV_SETUP ERROR] ‚ùå Fall√≥ la inicializaci√≥n: {e}")
    import traceback
    traceback.print_exc()