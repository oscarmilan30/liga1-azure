{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4d51ef2-f83d-4b2c-b9b8-5f7b4db3fd41",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# UDV - HM_TABLAS_CLASIFICACION\n",
    "# Proyecto: Liga 1 Perú\n",
    "# Autor: Oscar García Del Águila\n",
    "# ==========================================================\n",
    "\n",
    "from env_setup import *\n",
    "from utils_liga1 import (\n",
    "    setup_adls, get_dbutils, get_predecesor, get_pipeline_params,\n",
    "    get_yaml_from_param, read_udv_table, get_pipeline,\n",
    "    write_delta_udv, log, is_dataframe_empty, get_entity_data\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "from hm_tablas_clasificacion import  carga_final_hm_tablas_clasificacion\n",
    "import traceback\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# CONFIG BASICA\n",
    "# ----------------------------------------------------------\n",
    "log(\"Inicio pipeline HM_TABLAS_CLASIFICACION\", \"INFO\",\"hm_tablas_clasificacion\")\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "setup_adls()\n",
    "dbutils = get_dbutils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84d5bdc9-1d58-473e-ab9c-830687286ad0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# PARÁMETROS Y PREDECESORES\n",
    "# ----------------------------------------------------------\n",
    "try:\n",
    "    # Para pruebas en notebook; en ADF se setea dinámicamente\n",
    "    dbutils.widgets.text(\"prm_pipelineid\", \"20\")\n",
    "    prm_pipelineid = int(dbutils.widgets.get(\"prm_pipelineid\"))\n",
    "\n",
    "    pipeline_info    = get_pipeline(prm_pipelineid)\n",
    "    entity_name      = pipeline_info[\"pipeline\"]          # 'hm_tablas_clasificacion'\n",
    "\n",
    "    dict_predecesores = get_predecesor(prm_pipelineid)\n",
    "    dict_params       = get_pipeline_params(prm_pipelineid)\n",
    "\n",
    "    # Predecesores:\n",
    "    #  - md_catalogo_equipos     -> RutaTabla = 'tb_udv.md_catalogo_equipos'\n",
    "    #  - tablas_clasificacion    -> RutaTabla = 'tablas_clasificacion' (RAW)\n",
    "    prm_tabla_md_catalogo_equipos = dict_predecesores[\"md_catalogo_equipos\"][\"RutaTabla\"]\n",
    "    entity_raw_clasificacion      = dict_predecesores[\"tablas_clasificacion\"][\"RutaTabla\"]\n",
    "\n",
    "    # Parámetros UDV\n",
    "    prm_capa_udv     = dict_params[\"CAPA_UDV\"]\n",
    "    prm_ruta_base    = dict_params[\"RUTA_BASE\"]\n",
    "    prm_ruta_tabla   = dict_params[\"RUTA_TABLA\"]\n",
    "    prm_formato      = dict_params[\"FORMATO_SALIDA\"]\n",
    "    prm_schema_tb    = dict_params[\"SCHEMA_TABLA\"]\n",
    "    prm_tabla_output = dict_params[\"NOMBRE_TABLA\"]\n",
    "    prm_ruta_yaml    = dict_params[\"YAML_PATH\"]\n",
    "\n",
    "    log(\"Parámetros cargados correctamente\", \"INFO\", entity_name)\n",
    "\n",
    "except Exception as e:\n",
    "    log(f\"Error al cargar parámetros o predecesores: {e}\", \"ERROR\", entity_name)\n",
    "    print(traceback.format_exc())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b60d31f-f356-47d0-969c-e837ca158a39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# LECTURA YAML\n",
    "# ----------------------------------------------------------\n",
    "try:\n",
    "    yaml_conf = get_yaml_from_param(prm_ruta_yaml)\n",
    "\n",
    "    prm_campo_json                 = yaml_conf[entity_name][\"campo_json\"]\n",
    "    prm_cols_raw_clasificacion_hm  = yaml_conf[entity_name][\"cols_raw_clasificacion_hm\"]\n",
    "    prm_rename_columns_hm          = yaml_conf[entity_name][\"rename_columns_hm\"]\n",
    "    prm_schema_hm                  = yaml_conf[entity_name][\"schema_hm\"]\n",
    "\n",
    "    log(\"YAML cargado correctamente\", \"INFO\", entity_name)\n",
    "\n",
    "except Exception as e:\n",
    "    log(f\"Error al leer YAML {prm_ruta_yaml}: {e}\", \"ERROR\", entity_name)\n",
    "    print(traceback.format_exc())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4130cb9-805f-4b7e-a55d-9b1c159775a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# LECTURA PREDECESORES (MD_CATALOGO_EQUIPOS + RAW JSON)\n",
    "# ----------------------------------------------------------\n",
    "try:\n",
    "    log(\"Lectura de predecesores\", \"INFO\", entity_name)\n",
    "\n",
    "    # 1) MD_CATALOGO_EQUIPOS\n",
    "    df_md_catalogo_equipos = read_udv_table(prm_tabla_md_catalogo_equipos)\n",
    "    if is_dataframe_empty(df_md_catalogo_equipos):\n",
    "        raise Exception(f\"No se encontró data en: {prm_tabla_md_catalogo_equipos}\")\n",
    "\n",
    "    # 2) RAW tablas_clasificacion desde tbl_paths (flg_udv = 'N') + JSON\n",
    "    df_raw = get_entity_data(entity_raw_clasificacion)\n",
    "    if is_dataframe_empty(df_raw):\n",
    "        raise Exception(\"RAW vacío\")\n",
    "\n",
    "    log(\"Predecesores completados correctamente\", \"INFO\", entity_name)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    log(f\"Error en lectura de predecesores/RAW: {e}\", \"ERROR\", entity_name)\n",
    "    print(traceback.format_exc())\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbcdc8a1-3079-4a22-a3c1-605295a9fc2d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# EJECUCIÓN PRINCIPAL\n",
    "# ----------------------------------------------------------\n",
    "try:\n",
    "    log(\"Inicio de Ejecución Principal\", \"INFO\", entity_name)\n",
    "\n",
    "    df_final_hm = carga_final_hm_tablas_clasificacion(\n",
    "    df_raw=df_raw,\n",
    "    df_md_catalogo_equipos=df_md_catalogo_equipos,\n",
    "    prm_cols_raw_clasificacion_hm=prm_cols_raw_clasificacion_hm,\n",
    "    prm_rename_columns_hm=prm_rename_columns_hm,\n",
    "    prm_schema_hm=prm_schema_hm,\n",
    "    campo_json=prm_campo_json\n",
    "    )\n",
    "\n",
    "\n",
    "    if is_dataframe_empty(df_final_hm):\n",
    "        log(\"df_final_hm vacío, no se realizará escritura en UDV\", \"WARN\", entity_name)\n",
    "    else:\n",
    "        log(\"Escribiendo HM_TABLAS_CLASIFICACION con overwrite dinámico por partición [periodo]\", \"INFO\", entity_name)\n",
    "\n",
    "        write_delta_udv(\n",
    "            spark,\n",
    "            df_final_hm,\n",
    "            prm_schema_tb,          # ej: 'tb_udv'\n",
    "            prm_tabla_output,       # ej: 'hm_tablas_clasificacion'\n",
    "            mode=\"overwrite\",\n",
    "            partition_by=[\"periodo\"],\n",
    "            overwrite_dynamic_partition=True\n",
    "        )\n",
    "\n",
    "        log(\"Escritura HM_TABLAS_CLASIFICACION completada\", \"SUCCESS\", entity_name)\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    log(f\"Error en ejecución principal: {e}\", \"ERROR\", entity_name)\n",
    "    print(traceback.format_exc())\n",
    "    raise\n",
    "\n",
    "log(\"Finalización del pipeline UDV\", \"INFO\", entity_name)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_hm_tablas_clasificacion",
   "widgets": {
    "prm_pipelineid": {
     "currentValue": "20",
     "nuid": "7bba292a-b9e6-4e50-8fef-a126c5aecc7d",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "20",
      "label": null,
      "name": "prm_pipelineid",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "20",
      "label": null,
      "name": "prm_pipelineid",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
