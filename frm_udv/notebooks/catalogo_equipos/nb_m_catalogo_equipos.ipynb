{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4be45e1-bed0-4cb2-a372-c8163851c7ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# ==========================================================\n",
    "# UDV - CATALOGO_EQUIPOS\n",
    "# Proyecto: Liga 1 Perú\n",
    "# Autor: Oscar García Del Águila\n",
    "# ==========================================================\n",
    "\n",
    "from env_setup import *\n",
    "from pyspark.sql import SparkSession\n",
    "from utils_liga1 import setup_adls, get_dbutils, get_abfss_path, read_parquet_adls, is_dataframe_empty,get_predecesor, get_pipeline_params,get_yaml_from_param\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# CONFIGURACIÓN DE ADLS Y SPARK\n",
    "# ----------------------------------------------------------\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "setup_adls()\n",
    "dbutils = get_dbutils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b641e0-d341-427a-b7e6-47877c0dbb53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------\n",
    "# LECTURA PRECESORES Y PARAMETROS AZURE SQL DATABASE\n",
    "# ----------------------------------------------------------\n",
    "dict_predecesores = get_predecesor(4)\n",
    "dict_params = get_pipeline_params(4)\n",
    "\n",
    "\n",
    "prm_ruta_predecesor=dict_predecesores['Ruta_Predecesor']\n",
    "prm_ruta_yaml=dict_params[\"YAML_PATH\"]\n",
    "\n",
    "yaml_conf = get_yaml_from_param(prm_ruta_yaml)\n",
    "\n",
    "ruta_abfss_origen = get_abfss_path(prm_ruta_predecesor)\n",
    "print(yaml_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aca7bb14-ff33-4ed8-bced-e7ac04fbc746",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # ----------------------------------------------------------\n",
    "# # EJECUCIÓN SEGURA\n",
    "# # ----------------------------------------------------------\n",
    "# try:\n",
    "#     print(\"===== LECTURA DESDE RAW/DATA =====\")\n",
    "#     df = read_parquet_adls(spark, ruta_abfss_origen)\n",
    "\n",
    "#     # Validar si el DataFrame está vacío antes de procesar\n",
    "#     if is_dataframe_empty(df):\n",
    "#         raise Exception(f\"No se encontró data en la ruta origen: {ruta_abfss_origen}\")\n",
    "\n",
    "\n",
    "# except Exception as e:\n",
    "#     print(\"Error :\", str(e))\n",
    "#     import traceback\n",
    "#     print(traceback.format_exc())\n",
    "#     raise"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nb_m_catalogo_equipos",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
